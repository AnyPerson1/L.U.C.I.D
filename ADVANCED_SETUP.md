# Advanced Setup Guide - VITS, NeMo ve Ollama

Bu rehber, Jarvis iÃ§in geliÅŸmiÅŸ TTS/STT motorlarÄ± ve lokal AI modellerinin kurulumunu aÃ§Ä±klar.

## ğŸ¯ NVIDIA NeMo ASR Kurulumu

### Sistem Gereksinimleri
- NVIDIA GPU (CUDA desteÄŸi)
- CUDA 11.8+ veya 12.x
- Python 3.8-3.10
- 8GB+ GPU RAM (Ã¶nerilen)

### Kurulum AdÄ±mlarÄ±

```bash
# 1. NeMo Toolkit kurulumu
pip install nemo_toolkit[asr]

# 2. Ek baÄŸÄ±mlÄ±lÄ±klar
pip install omegaconf hydra-core
pip install pytorch-lightning>=1.9.0

# 3. CUDA uyumluluÄŸu iÃ§in
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Test Etme
```python
import nemo.collections.asr as nemo_asr
model = nemo_asr.models.EncDecCTCModel.from_pretrained("nvidia/stt_en_conformer_ctc_large")
print("NeMo ASR baÅŸarÄ±yla yÃ¼klendi!")
```

## ğŸµ VITS TTS Kurulumu

### Manuel Kurulum (GeliÅŸmiÅŸ)

```bash
# 1. VITS repository'sini klonla
git clone https://github.com/jaywalnut310/vits.git
cd vits

# 2. Gerekli paketleri yÃ¼kle
pip install torch torchaudio
pip install scipy matplotlib
pip install phonemizer
pip install librosa
pip install unidecode

# 3. Monotonic Alignment Search derle
cd monotonic_align
python setup.py build_ext --inplace
cd ..
```

### Pre-trained Model Ä°ndirme
```bash
# LJ Speech modeli (Ä°ngilizce)
wget https://drive.google.com/uc?id=1q86w74Ygw2hNzYP9cWkeClGT5X25PvBT -O vits_ljs_base.pth

# Model dosyalarÄ±nÄ± Jarvis klasÃ¶rÃ¼ne taÅŸÄ±
mkdir -p "C:\Users\LUCID\Desktop\Jarvis V1\vits_models"
move vits_ljs_base.pth "C:\Users\LUCID\Desktop\Jarvis V1\vits_models\"
```

### VITS KonfigÃ¼rasyonu
```json
{
  "model_path": "./vits_models/vits_ljs_base.pth",
  "config_path": "./vits_models/config.json",
  "vocab_path": "./vits_models/vocab.txt"
}
```

## ğŸ¤– Ollama Phi-4-Mini Kurulumu

### 1. Ollama Kurulumu
```bash
# Windows iÃ§in Ollama indirin:
# https://ollama.ai/download/windows

# Kurulum sonrasÄ± terminal'de:
ollama --version
```

### 2. Phi-4-Mini Model Ä°ndirme
```bash
# Phi-4-Mini modelini Ã§ek (yaklaÅŸÄ±k 2.4GB)
ollama pull phi3:mini

# Alternatif olarak daha bÃ¼yÃ¼k model:
ollama pull phi3:medium
```

### 3. Model Test Etme
```bash
# Modeli test et
ollama run phi3:mini "Hello, how are you?"
```

### 4. API Endpoint Test
```bash
# REST API test
curl http://localhost:11434/api/generate -d '{
  "model": "phi3:mini",
  "prompt": "Why is the sky blue?",
  "stream": false
}'
```

## âš™ï¸ Jarvis KonfigÃ¼rasyonu

Jarvis'te bu motorlarÄ± aktifleÅŸtirmek iÃ§in `jarvis.py` dosyasÄ±ndaki CONFIG bÃ¶lÃ¼mÃ¼nÃ¼ gÃ¼ncelleyin:

```python
CONFIG = {
    "TTS_ENGINE": "vits",  # "coqui", "pyttsx3", "mimic3", "vits"
    "STT_ENGINE": "nemo",  # "whisper", "nemo"
    "USE_OLLAMA": True,    # Ollama kullanÄ±mÄ±
    "OLLAMA_MODEL": "phi3:mini",  # Ollama model adÄ±
    "OLLAMA_URL": "http://localhost:11434",  # Ollama server URL
}
```

## ğŸ”§ Sorun Giderme

### NeMo SorunlarÄ±
```bash
# CUDA uyumluluk sorunu
pip uninstall torch torchaudio
pip install torch==2.1.0+cu121 torchaudio==2.1.0+cu121 --index-url https://download.pytorch.org/whl/cu121

# Memory hatasÄ±
export CUDA_VISIBLE_DEVICES=0
```

### VITS SorunlarÄ±
```bash
# Phonemizer hatasÄ± (Windows)
# Espeak-ng yÃ¼kleyin: https://github.com/espeak-ng/espeak-ng/releases

# Monotonic align hatasÄ±
cd monotonic_align
rm -rf build/
python setup.py clean --all
python setup.py build_ext --inplace
```

### Ollama SorunlarÄ±
```bash
# Service baÅŸlatma
ollama serve

# Port deÄŸiÅŸtirme
set OLLAMA_HOST=0.0.0.0:11435
ollama serve
```

## ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Motor | HÄ±z | Kalite | GPU Gereksinimi | Disk AlanÄ± |
|-------|-----|--------|----------------|-------------|
| Whisper | Orta | YÃ¼ksek | Opsiyonel | 1-3GB |
| NeMo | HÄ±zlÄ± | Ã‡ok YÃ¼ksek | Gerekli | 500MB-2GB |
| Coqui TTS | Orta | Ä°yi | Opsiyonel | 100-500MB |
| VITS | HÄ±zlÄ± | Ã‡ok YÃ¼ksek | Ã–nerilen | 100-300MB |
| Ollama Phi-4 | HÄ±zlÄ± | YÃ¼ksek | Ã–nerilen | 2.4GB |

## ğŸ¯ Ã–nerilen KonfigÃ¼rasyonlar

### YÃ¼ksek Performans (GPU Gerekli)
```python
CONFIG = {
    "TTS_ENGINE": "vits",
    "STT_ENGINE": "nemo", 
    "USE_OLLAMA": True,
    "OLLAMA_MODEL": "phi3:mini"
}
```

### Orta Performans (GPU Opsiyonel)
```python
CONFIG = {
    "TTS_ENGINE": "coqui",
    "STT_ENGINE": "whisper",
    "USE_OLLAMA": True,
    "OLLAMA_MODEL": "phi3:mini"
}
```

### DÃ¼ÅŸÃ¼k Kaynak (CPU Only)
```python
CONFIG = {
    "TTS_ENGINE": "pyttsx3",
    "STT_ENGINE": "whisper",
    "USE_OLLAMA": False  # Gemini kullan
}
```

## ğŸ“ Notlar

- NeMo ve VITS GPU kullanÄ±mÄ±nÄ± Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rÄ±r
- Ollama lokal Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in internet baÄŸlantÄ±sÄ± gerektirmez
- Phi-4-Mini modeli 2.4GB disk alanÄ± kaplar
- TÃ¼m motorlar aynÄ± anda kullanÄ±labilir (fallback sistemi ile)

Bu kurulumlar tamamlandÄ±ktan sonra Jarvis Ã§ok daha geliÅŸmiÅŸ yeteneklere sahip olacak!